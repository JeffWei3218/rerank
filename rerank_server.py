from fastapi import FastAPI, HTTPException, Header, Depends
from pydantic import BaseModel, Field
from typing import List, Optional
import uvicorn
from sentence_transformers import CrossEncoder
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="VLLM Rerank API",
    description="å…¼å®¹ VLLM æ ¼å¼çš„ Rerank æœåŠ¡",
    version="1.0.0"
)

# å…¨å±€å˜é‡
rerank_models = {}  # æ¨¡å‹ç¼“å­˜å­—å…¸ {model_name: CrossEncoder}
default_model_name = None  # é»˜è®¤æ¨¡å‹åç§°
API_KEY = os.getenv("RERANK_API_KEY", "")  # ä»ç¯å¢ƒå˜é‡è¯»å– API Key

# æ”¯æŒçš„æ¨¡å‹é…ç½®
SUPPORTED_MODELS = {
    "BAAI/bge-reranker-base": {
        "local_path": "models/bge-reranker-base",
        "remote_name": "BAAI/bge-reranker-base",
        "max_length": 512
    },
    "BAAI/bge-reranker-large": {
        "local_path": "models/bge-reranker-large",
        "remote_name": "BAAI/bge-reranker-large",
        "max_length": 512
    },
    "BAAI/bge-reranker-v2-m3": {
        "local_path": "models/bge-reranker-v2-m3",
        "remote_name": "BAAI/bge-reranker-v2-m3",
        "max_length": 512
    }
}

# è¯·æ±‚æ¨¡å‹ï¼ˆå…¼å®¹ VLLM æ ¼å¼ï¼‰
class RerankRequest(BaseModel):
    query: str = Field(..., description="æŸ¥è¯¢æ–‡æœ¬")
    documents: List[str] = Field(..., description="å¾…é‡æ’çš„æ–‡æ¡£åˆ—è¡¨")
    model: Optional[str] = Field("BAAI/bge-reranker-base", description="æ¨¡å‹åç§°ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼‰")
    top_n: Optional[int] = Field(None, description="è¿”å›å‰ n ä¸ªç»“æœ")

# å“åº”æ¨¡å‹ï¼ˆå…¼å®¹ VLLM æ ¼å¼ï¼‰
class RerankResultItem(BaseModel):
    index: int = Field(..., description="æ–‡æ¡£åœ¨åŸå§‹åˆ—è¡¨ä¸­çš„ç´¢å¼•")
    relevance_score: float = Field(..., description="ç›¸å…³æ€§åˆ†æ•°")

class RerankResponse(BaseModel):
    results: List[RerankResultItem] = Field(..., description="é‡æ’ç»“æœåˆ—è¡¨")

# API Key éªŒè¯ï¼ˆå¯é€‰ï¼‰
async def verify_api_key(authorization: Optional[str] = Header(None)):
    """éªŒè¯ API Keyï¼ˆå¦‚æœè®¾ç½®äº†çš„è¯ï¼‰"""
    if API_KEY:  # åªæœ‰è®¾ç½®äº† API_KEY æ‰éªŒè¯
        if not authorization:
            raise HTTPException(status_code=401, detail="æœªæä¾› Authorization header")
        
        # æ”¯æŒ "Bearer <token>" æ ¼å¼
        if authorization.startswith("Bearer "):
            token = authorization[7:]
        else:
            token = authorization
        
        if token != API_KEY:
            raise HTTPException(status_code=401, detail="æ— æ•ˆçš„ API Key")
    
    return True

def load_single_model(model_name: str) -> CrossEncoder:
    """
    åŠ è½½å•ä¸ªæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        åŠ è½½å¥½çš„ CrossEncoder æ¨¡å‹
    """
    if model_name not in SUPPORTED_MODELS:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. æ”¯æŒçš„æ¨¡å‹: {list(SUPPORTED_MODELS.keys())}")
    
    config = SUPPORTED_MODELS[model_name]
    local_path = config["local_path"]
    remote_name = config["remote_name"]
    max_length = config["max_length"]
    
    # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
    if os.path.exists(local_path) and os.path.isdir(local_path):
        logger.info(f"âœ… å‘ç°æœ¬åœ°æ¨¡å‹: {local_path}")
        model_path = local_path
    else:
        logger.info(f"âš ï¸  æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨: {local_path}")
        logger.info(f"æ­£åœ¨ä» Hugging Face ä¸‹è½½: {remote_name}")
        model_path = remote_name
    
    model = CrossEncoder(model_path, max_length=max_length)
    logger.info(f"ğŸ‰ æ¨¡å‹ [{model_name}] åŠ è½½æˆåŠŸï¼")
    
    return model


@app.on_event("startup")
async def load_model():
    """å¯åŠ¨æ—¶åŠ è½½é»˜è®¤æ¨¡å‹"""
    global rerank_models, default_model_name
    try:
        # é»˜è®¤åŠ è½½ bge-reranker-large
        default_model_name = "BAAI/bge-reranker-large"
        
        logger.info(f"æ­£åœ¨åŠ è½½é»˜è®¤æ¨¡å‹: {default_model_name}")
        rerank_models[default_model_name] = load_single_model(default_model_name)
        
        # æ—¥å¿— API Key çŠ¶æ€
        if API_KEY:
            logger.info(f"ğŸ” API Key è®¤è¯å·²å¯ç”¨")
        else:
            logger.info(f"âš ï¸  æœªè®¾ç½® API Keyï¼ŒæœåŠ¡æ— éœ€è®¤è¯ï¼ˆä¸æ¨èç”Ÿäº§ç¯å¢ƒï¼‰")
        
        logger.info(f"âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼æ”¯æŒ {len(SUPPORTED_MODELS)} ä¸ªæ¨¡å‹")
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        raise

@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "running",
        "service": "VLLM Rerank API",
        "loaded_models": list(rerank_models.keys()),
        "default_model": default_model_name,
        "supported_models": list(SUPPORTED_MODELS.keys()),
        "authentication": "enabled" if API_KEY else "disabled"
    }

@app.post("/v1/rerank", response_model=RerankResponse)
async def rerank(
    request: RerankRequest,
    authorized: bool = Depends(verify_api_key)
):
    """
    é‡æ’æ–‡æ¡£æ¥å£ï¼ˆå…¼å®¹ VLLM æ ¼å¼ï¼‰
    
    Args:
        request: åŒ…å« queryã€documents å’Œå¯é€‰å‚æ•°
        authorized: API Key éªŒè¯ç»“æœ
    
    Returns:
        é‡æ’åçš„æ–‡æ¡£åˆ—è¡¨ï¼ˆåªåŒ…å« index å’Œ relevance_scoreï¼‰
    """
    global rerank_models, default_model_name
    
    if not request.documents:
        raise HTTPException(status_code=400, detail="æ–‡æ¡£åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    try:
        # ç¡®å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹
        model_name = request.model or default_model_name
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ
        if model_name not in SUPPORTED_MODELS:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. æ”¯æŒçš„æ¨¡å‹: {list(SUPPORTED_MODELS.keys())}"
            )
        
        # å¦‚æœæ¨¡å‹æœªåŠ è½½ï¼ŒåŠ¨æ€åŠ è½½
        if model_name not in rerank_models:
            logger.info(f"ğŸ”„ æ¨¡å‹ [{model_name}] æœªåŠ è½½ï¼Œæ­£åœ¨åŠ¨æ€åŠ è½½...")
            rerank_models[model_name] = load_single_model(model_name)
        
        model = rerank_models[model_name]
        
        logger.info(
            f"æ”¶åˆ°é‡æ’è¯·æ±‚ - query: '{request.query[:50]}...', "
            f"documents: {len(request.documents)}ä¸ª, "
            f"model: {model_name}, "
            f"top_n: {request.top_n}"
        )
        
        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        pairs = [[request.query, doc] for doc in request.documents]
        
        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = model.predict(pairs)
        
        # åˆ›å»ºç»“æœåˆ—è¡¨
        results = [
            RerankResultItem(
                index=idx,
                relevance_score=float(score)
            )
            for idx, score in enumerate(scores)
        ]
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        
        # å¦‚æœæŒ‡å®šäº† top_nï¼Œåªè¿”å›å‰ n ä¸ª
        if request.top_n is not None and request.top_n > 0:
            results = results[:request.top_n]
        
        # è®°å½•æœ€ç»ˆè¿”å›çš„ç´¢å¼•ä¸åˆ†æ•°
        try:
            return_scores_str = ", ".join([
                f"rank={i+1}->idx={r.index}: {r.relevance_score:.6f}"
                for i, r in enumerate(results)
            ]) or "(empty)"
            logger.info(
                f"âœ… é‡æ’å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç»“æœï¼ˆä½¿ç”¨æ¨¡å‹: {model_name}ï¼‰ - è¿”å›åˆ—è¡¨: {return_scores_str}"
            )
        except Exception:
            logger.info(f"âœ… é‡æ’å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç»“æœï¼ˆä½¿ç”¨æ¨¡å‹: {model_name}ï¼‰")
        
        return RerankResponse(results=results)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ é‡æ’å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é‡æ’å¤±è´¥: {str(e)}")

@app.get("/v1/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
    return {
        "data": [
            {
                "id": model_name,
                "object": "model",
                "owned_by": "BAAI" if "BAAI" in model_name else "unknown",
                "loaded": model_name in rerank_models,
                "local_available": os.path.exists(config["local_path"])
            }
            for model_name, config in SUPPORTED_MODELS.items()
        ]
    }

if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡ï¼ˆé»˜è®¤ç«¯å£ 8000ï¼Œå…¼å®¹ VLLMï¼‰
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )